{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b5251c2f129c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#!{sys.executable} -m pip install geopandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m#import  install altair.vegalite.v2 as alt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "# %load active_business_script.py\n",
    "\"\"\"\n",
    "Created on Wed May  1 08:51:03 2019\n",
    "\n",
    "@author: myrfid041\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "pwd=os.getcwd()\n",
    "import sys\n",
    "#!{sys.executable} -m pip install sodapy\n",
    "from sodapy import Socrata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#!{sys.executable} -m pip install geopandas\n",
    "import geopandas as gpd\n",
    "#import  install altair.vegalite.v2 as alt\n",
    "import folium\n",
    "import xlsxwriter\n",
    "from shapely.geometry import Point\n",
    "#!{sys.executable} -m pip install arcgis\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features.summarize_data import join_features\n",
    "import json\n",
    "import credentials\n",
    "from IPython.display import display\n",
    "from arcgis.features import FeatureLayer\n",
    "from arcgis.features import FeatureLayerCollection\n",
    "import json\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Setting the Outputs\n",
    "ABOutput=pwd+'/Listing_of_Active_Businesses.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "#---Pulling Active Business Data\n",
    "client = Socrata(\"data.lacity.org\", None)\n",
    "\n",
    "abiz = pd.DataFrame(client.get('ngkp-kqkn', limit=10000000))\n",
    "\n",
    "abiz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naics_sector</th>\n",
       "      <th>naics_industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Agriculture, Forestry, Fishing and Hunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>Mining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Utilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>Construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>Manufacturing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   naics_sector                              naics_industry\n",
       "0            11  Agriculture, Forestry, Fishing and Hunting\n",
       "1            21                                      Mining\n",
       "2            22                                   Utilities\n",
       "3            23                                Construction\n",
       "4            31                               Manufacturing"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---Pull NAIC Industry Table\n",
    "n_table=pwd+'/naics_industry_table.csv'\n",
    "naics_table=pd.read_csv(n_table)\n",
    "naics_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n, z):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        chunk_list=l[i:i + n]\n",
    "        z.edit_features(updates= chunk_list)\n",
    "        print(\"update successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abOutput(x):\n",
    "    x.to_csv(ABOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10(x):\n",
    "    x.pred_ind=x.idxmax(axis=1)\n",
    "    predom_industries=pd.DataFrame(x.pred_ind.value_counts())[0:12]\n",
    "    predom_industries=predom_industries.index.tolist()\n",
    "    predom_industries.remove('Professional, Scientific, and Technical Services');\n",
    "    predom_industries.remove('Other Services (except Public Administration)');\n",
    "    return predom_industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataprep(x):\n",
    "    df=x\n",
    "    df=df.dropna(subset=['location_1','naics'])\n",
    "    df['location_2']=df['location_1'].astype('str') #Prepping location data to parse (x,y) values\n",
    "    df['location_2']=df['location_2'].str[34:-2]\n",
    "    locations = df[\"location_2\"].str.split(\",\", n = 1, expand = True) #Creating a dataframe with x,y coordinates\n",
    "    locations[1] =locations[1].str[1:]\n",
    "    df['lon']=locations[0]\n",
    "    df['lat']=locations[1]\n",
    "    df=df.dropna(subset=['lat','lon'])\n",
    "    df['naics_sector'] = df['naics'].str[:2].astype('str')\n",
    "    dfn=naics_table\n",
    "    dfn['naics_sector']=dfn['naics_sector'].astype('str')\n",
    "    df2=pd.merge(df,dfn,how='inner',on='naics_sector',validate='m:1')\n",
    "    df2.lon=df.lon.astype(float)\n",
    "    df2.lat=df.lat.astype(float)\n",
    "    # Create geometry column\n",
    "    df2['geometry'] = df2.apply(\n",
    "        lambda row: Point(row.lon, row.lat), axis=1)\n",
    "    # Rename columns\n",
    "    df2.rename(columns = {'lon': 'longitude', 'lat':'latitude'}, inplace=True)\n",
    "    df2=df2.dropna(subset=['longitude','latitude'])\n",
    "    gdf = gpd.GeoDataFrame(df2, geometry = 'geometry')\n",
    "    # Set CRS\n",
    "    gdf.crs = {'init':'epsg:4326'}\n",
    "    # Drop NAs, then project to CA State Plane\n",
    "    gdf = gdf[gdf.geometry.notna()]\n",
    "    gdf = gdf.to_crs({'init':'epsg:2229'})\n",
    "    block = gpd.read_file('./LACounty_Blockgroup/')\n",
    "    block.crs={'init':'epsg:2229'}\n",
    "    sjoin=gpd.sjoin(gdf,block,how='inner',op='intersects')\n",
    "    sjoin2=sjoin.pivot_table(index='GEOID10',values='business_name',columns=['naics_industry'],aggfunc=len)\n",
    "    sjoin2=sjoin2.fillna(0)\n",
    "    abOutput(sjoin2)\n",
    "    predom_ind=top10(sjoin2)\n",
    "    return predom_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go():\n",
    "    predom=dataprep(abiz)\n",
    "    updated_csv_df = pd.read_csv(ABOutput)\n",
    "    updated_csv_df['GEOID10']=updated_csv_df['GEOID10'].astype(str)\n",
    "    updated_csv_df.dtypes\n",
    "    updated_csv_df['GEOID10'] = updated_csv_df['GEOID10'].apply(lambda x: '{0:0>12}'.format(x))\n",
    "    geohub_updates(updated_csv_df,credentials.lahub_user,credentials.lahub_pass,predom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_desc(x,y,z):\n",
    "    active_biz=z.content.get(y)    \n",
    "    text = \"\"\"\n",
    "    This layer is aggregating <a href=\"https://data.lacity.org/A-Prosperous-City/Listing-of-Active-Businesses/6rrh-rzua\">Listing of Active Businesses Data</a> that have geospatial information associated. The top 10 most frequent industries in block groups are:\n",
    "    {}\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    item_props = {'title' : 'Active Businesses Data by Block Group', 'description':text.format(x)}\n",
    "    active_biz.update(item_properties=item_props)\n",
    "    print(\"updates made!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geohub_updates(x,user,pas,topz):\n",
    "    gis = GIS('https://lahub.maps.arcgis.com',  username=user, password=pas)\n",
    "    output_layer_name = '067a9242fbef4afeb1ca0744952e5724'\n",
    "    actbus=gis.content.search(output_layer_name)\n",
    "    ActiveBusinesses_item = actbus[0]\n",
    "    ActiveBusinesses_flayer = ActiveBusinesses_item.layers[0]\n",
    "    ActiveBusinesses_flayer\n",
    "    ActiveBusinesses_fset = ActiveBusinesses_flayer.query() #querying without any conditions returns all the features\n",
    "    ActiveBusinesses_fset.sdf.head()\n",
    "    ActiveBusinesses_fset.sdf.shape\n",
    "    ActiveBusinesses_fset.sdf.dtypes\n",
    "    overlap_rows = pd.merge(left = ActiveBusinesses_fset.sdf, \n",
    "                        right = x, \n",
    "                        how='inner',\n",
    "                        on = 'GEOID10')\n",
    "    overlap_rows.head(5)\n",
    "\n",
    "    # overlap_rows.to_csv(\"C:\\\\Users\\\\mad10412\\\\Desktop\\\\Merged.csv\")\n",
    "    overlap_rows.shape\n",
    "\n",
    "    #Perform updates\n",
    "\n",
    "    features_for_update = [] #list containing corrected features\n",
    "    all_features = ActiveBusinesses_fset.features\n",
    "\n",
    "    for GEOID10 in overlap_rows['GEOID10']:\n",
    "        # get the feature to be updated\n",
    "        original_feature = [f for f in all_features if f.attributes['GEOID10'] == GEOID10][0]\n",
    "        feature_to_be_updated = deepcopy(original_feature)\n",
    "\n",
    "        # get the matching row from csv\n",
    "        matching_row = x.where(x.GEOID10 == GEOID10).dropna()\n",
    "\n",
    "        # assign the updated values\n",
    "        feature_to_be_updated.attributes['Accommodation_and_Food_Services'] = matching_row['Accommodation and Food Services'].values[0]\n",
    "        feature_to_be_updated.attributes['Administrative_and_Support_and_'] = matching_row['Administrative and Support and Waste Management and Remediation Services'].values[0]\n",
    "        feature_to_be_updated.attributes['Agriculture__Forestry__Fishing_'] = matching_row['Agriculture, Forestry, Fishing and Hunting'].values[0]\n",
    "        feature_to_be_updated.attributes['Arts__Entertainment__and_Recrea'] = matching_row['Arts, Entertainment, and Recreation'].values[0]\n",
    "        feature_to_be_updated.attributes['Construction'] = matching_row['Construction'].values[0]\n",
    "        feature_to_be_updated.attributes['Educational_Services'] = matching_row['Educational Services'].values[0]\n",
    "        feature_to_be_updated.attributes['Finance_and_Insurance'] = matching_row['Finance and Insurance'].values[0]\n",
    "        feature_to_be_updated.attributes['Health_Care_and_Social_Assistan'] = matching_row['Health Care and Social Assistance'].values[0]\n",
    "        feature_to_be_updated.attributes['Information'] = matching_row['Information'].values[0]\n",
    "        feature_to_be_updated.attributes['Manufacturing'] = matching_row['Manufacturing'].values[0]\n",
    "        feature_to_be_updated.attributes['Medical_Marijuana_Collective'] = matching_row['Medical Marijuana Collective'].values[0]\n",
    "        feature_to_be_updated.attributes['Mining'] = matching_row['Mining'].values[0]\n",
    "        feature_to_be_updated.attributes['Not_Classified'] = matching_row['Not Classified'].values[0]\n",
    "        feature_to_be_updated.attributes['Other_Services__except_Public_A'] = matching_row['Other Services (except Public Administration)'].values[0]\n",
    "        feature_to_be_updated.attributes['Professional__Scientific__and_T'] = matching_row['Professional, Scientific, and Technical Services'].values[0]\n",
    "        feature_to_be_updated.attributes['Real_Estate_Rental_and_Leasing'] = matching_row['Real Estate Rental and Leasing'].values[0]\n",
    "        feature_to_be_updated.attributes['Retail_Trade'] = matching_row['Retail Trade'].values[0]\n",
    "        feature_to_be_updated.attributes['Transportation_and_Warehousing'] = matching_row['Transportation and Warehousing'].values[0]\n",
    "        feature_to_be_updated.attributes['Utilities'] = matching_row['Utilities'].values[0]\n",
    "        feature_to_be_updated.attributes['Wholesale_Trade'] = matching_row['Wholesale Trade'].values[0]\n",
    "\n",
    "        #add this to the list of features to be updated\n",
    "        features_for_update.append(feature_to_be_updated)\n",
    "    chunks(features_for_update, 1000,ActiveBusinesses_flayer)\n",
    "    update_desc(topz,output_layer_name,gis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update successful\n",
      "update successful\n",
      "update successful\n",
      "update successful\n",
      "update successful\n",
      "update successful\n",
      "update successful\n",
      "CPU times: user 3min 57s, sys: 2.98 s, total: 3min 59s\n",
      "Wall time: 7min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "\tgo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
